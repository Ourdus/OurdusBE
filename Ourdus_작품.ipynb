{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement request (from versions: none)\n",
      "ERROR: No matching distribution found for request\n"
     ]
    }
   ],
   "source": [
    "pip install request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulSoup4 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from beautifulSoup4) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ksy\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\ksy\\anaconda3\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: configparser in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from webdriver-manager) (5.0.1)\n",
      "Requirement already satisfied: crayons in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.24.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.25.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-9655819ad17b>:37: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(tabs[0])\n",
      "<ipython-input-3-9655819ad17b>:58: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(tabs[1]) #ë‘ë²ˆì§¸ íƒ­ìœ¼ë¡œ ì´ë™\n",
      "<ipython-input-3-9655819ad17b>:84: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(tabs[2]) #ì„¸ë²ˆì§¸ íƒ­ìœ¼ë¡œ ì´ë™\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 'â¤ì„¤ë‚ ì„ ë¬¼ì„¸íŠ¸í• ì¸ (2/8ë°œì†¡)â¤ ë”¸ê¸°ì²­ ë”¸ê¸°ìš°ìœ  ë¼ë–¼', 'ì´ˆì½”ì¨ë‹ˆìˆ˜ì œì²­ìˆ˜ì œê³¼ì¼ì²­', 12900, 451, 1443, 18993, 3]\n",
      "[1, 2, ' ì„¤ ì „ ìˆ˜ë ¹ â¤ í¬ì¥ë¬´ë£Œ â¤ ë°”ë¥¸ ë”¸ê¸°ì²­ ', 'í¬ì‹œì¦Œí…Œì´ë¸”', 12900, 451, 1111, 6230, 3]\n",
      "[1, 3, '[ì„¤ë‚ ì„ ë¬¼]ğŸŒ¸5ì¢…+1ì¢…ëœë¤ì¦ì •ğŸŒ¸ë¯¸ë‹ˆê½ƒì°¨5ì¢…ì„¸íŠ¸ğŸŒ¸', 'í”Œë¡œì¸', 21250, 743, 570, 10943, 3]\n",
      "[1, 4, 'âš¡ì„¤ë‚ ì „ìˆ˜ë ¹âš¡ë°œë Œíƒ€ì¸ì„¤ë‚ ì„ ë¬¼ë”ì¹˜ì»¤í”¼6ì¢…ì„ ë¬¼ì„¸íŠ¸ 3+1 ', 'ê·¸:ë•Œì»¤í”¼', 10300, 360, 584, 6152, 3]\n",
      "[1, 5, '[â­ì£¼ë§ì¶œê³ â­]ì•Œë¡ë‹¬ë¡ğŸ’•12ì¢…ë”ì¹˜ì»¤í”¼ì„¸íŠ¸', 'ë³´ë¥´ë”˜', 17900, 626, 1711, 16639, 3]\n",
      "[1, 6, 'ì£¼ë§ì¶œê³ ì„¤ë‚ ì„ ë¬¼ì„¸íŠ¸ë°œë Œíƒ€ì¸(1+1+1)ë”ì¹˜ì»¤í”¼', 'ê·¸:ë•Œì»¤í”¼', 12500, 437, 2172, 9530, 3]\n",
      "[1, 7, 'ì‹œìŒê³µì§œâ¤ï¸ê³ ì†Œí•œ ì—ìŠ¤í”„ë ˆì†Œ ì»¤í”¼ ì›ì•¡ 500ml', 'ì†Œë¸”ë§ì»¤í”¼', 11980, 419, 981, 4139, 3]\n",
      "[1, 8, '[â­ì£¼ë§ì¶œê³ â­]ì•Œë¡ë‹¬ë¡ğŸ’•24ì¢…ë”ì¹˜ì»¤í”¼ì„¸íŠ¸', 'ë³´ë¥´ë”˜', 35500, 1242, 1366, 17479, 3]\n",
      "[1, 9, '[ì„¤ë‚ ì„ ë¬¼]ğŸŒ¸ê½ƒì°¨ì§‘ê²Œì¦ì •+ê½ƒì°¨5ì¢…ìƒ˜í”Œì„¸íŠ¸ğŸŒ¸', 'ë³´ë‚˜í”Œë¡œ', 25000, 875, 53, 574, 3]\n",
      "[1, 10, 'ì„¤ë‚ ì „ìˆ˜ë ¹âš¡ë°œë Œíƒ€ì¸.ì„¤ë‚ ì„ ë¬¼ì„¸íŠ¸ ë”ì¹˜ì»¤í”¼ ë¬¸êµ¬ì œì‘íŒŒìš°ì¹˜', 'ê·¸:ë•Œì»¤í”¼', 1000, 35, 97, 2985, 3]\n",
      "[1, 11, '[ğŸ’–ì„¤ë‚ ëª…ì ˆì„ ë¬¼ì„¸íŠ¸] ì£¼ë§ì¶œê³ âš¡ï¸ ë”ì¹˜ì»¤í”¼ì„ ë¬¼ ğŸ', 'ë§ˆì¼“ì»´í¼ë‹ˆ', 37000, 1295, 78, 2715, 3]\n",
      "[1, 12, 'ì„¤ë‚ ì„ ë¬¼ ë”ì¹˜ì»¤í”¼ ì½œë“œë¸Œë£¨ì›ì•¡ì„¸íŠ¸', 'ë§ˆì´ë”ì¹˜ì»¤í”¼', 9900, 346, 1621, 9612, 3]\n",
      "[1, 13, 'ğŸ”¥ì˜¤ëŠ˜ë§ˆê°â—ì„¤ë‚ íŠ¹ê°€ğŸ”¥ëŒ€ìš©ëŸ‰ ë”ì¹˜ì»¤í”¼ ë°œë Œíƒ€ì¸ ì„ ë¬¼', 'ì—˜ë¦¬í€íŠ¸ì»¤í”¼ë©', 10500, 367, 2783, 7632, 3]\n",
      "[1, 14, 'ì„¤ë‚ ì„ ë¬¼ì„¸íŠ¸â¤ìˆ˜ì œì²­â¤ì„¤ë‚  ì„ ë¬¼ì„¸íŠ¸â¤ë‹µë¡€í’ˆâ¤ì„¤ë‚ â¤', 'ë•¡ê¸°ëŠ”ê³µë°©ìˆ˜ì œì²­', 10000, 350, 444, 5685, 3]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import sys\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/KSY/Desktop/chromedriver.exe')\n",
    "driver.get(\"https://www.idus.com\") #tab[0]\n",
    "driver.execute_script('window.open(\"about:blank\", \"_blank\");') #ì°½ 1ê°œë” ì—´ì–´ë†“ê¸° tab[1]\n",
    "driver.execute_script('window.open(\"about:blank\", \"_blank\");') \n",
    "tabs = driver.window_handles\n",
    "time.sleep(3)\n",
    "\n",
    "def scroll():\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        # ëê¹Œì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # 1ì´ˆ ëŒ€ê¸°\n",
    "        time.sleep(1)\n",
    "\n",
    "        # ìŠ¤í¬ë¡¤ ë‹¤ìš´ í›„ ìŠ¤í¬ë¡¤ ë†’ì´ ë‹¤ì‹œ ê°€ì ¸ì˜´\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "img_List=[]\n",
    "with open (\"ourdus_product.csv\", 'w', encoding='utf-8',newline=\"\") as fileWrite:\n",
    "    myWriter = csv.writer(fileWrite)\n",
    "    time.sleep(3)\n",
    "    driver.switch_to_window(tabs[0])\n",
    "    scroll()\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    myWriter.writerow([\"ì¹´í…Œê³ ë¦¬ì•„ì´ë””\",\"ì‘í’ˆì•„ì´ë””\",\"ì‘í’ˆì´ë¦„\",\"ì‘ê°€ì´ë¦„\",'ê°€ê²©','ì ë¦½ê¸ˆ','êµ¬ë§¤í›„ê¸°ìˆ˜','ì¦ê²¨ì°¾ê¸°ìˆ˜','ì˜µì…˜ìˆ˜'])\n",
    "       \n",
    "    category_list =  soup.findAll('div',{'class':'ui_grid__cols--6'}) #ëª¨ë“  ì¹´í…Œê³ ë¦¬ ëª©ë¡\n",
    "    \n",
    "    cid = 0\n",
    "    pid=0\n",
    "    for i in category_list:\n",
    "        cid+=1\n",
    "        if cid==2:\n",
    "            break\n",
    "        category = i.findAll('div',{'class':'ui_grid__item'})\n",
    "        category_id = cid\n",
    "        category_info = i.find('a',{'class':'area-txt'})\n",
    "        category_name = category_info.text\n",
    "        category_url = \"https://www.idus.com/\" + str(category_info[\"href\"])\n",
    "        \n",
    "        driver.switch_to_window(tabs[1]) #ë‘ë²ˆì§¸ íƒ­ìœ¼ë¡œ ì´ë™\n",
    "        driver.get(category_url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "        class_list = soup.findAll('div',{'class':'ui_grid__item'})\n",
    "        \n",
    "        for j in class_list:\n",
    "            pid+=1\n",
    "            if pid==15: \n",
    "                break\n",
    "            info_url = j.find({'a':'data-v-27ea337a'})\n",
    "            info_url = \"https://www.idus.com/\"+ str(info_url[\"href\"])\n",
    "            img_url = j.find('div',{'class':'product-thumb-img'})\n",
    "            img_url = img_url[\"style\"]\n",
    "            start=img_url.find('\\\"')\n",
    "            end = img_url.find('\\\"',start+1)\n",
    "            img_URL = img_url[start+1:end]\n",
    "            img_List.append(img_URL)\n",
    "            \n",
    "            #img_URLë¡œ ë¡œì»¬ ì €ì¥ì†Œì— ì‚¬ì§„ ì €ì¥\n",
    "            with urlopen(img_URL) as f:\n",
    "                with open('./Ourdus/product_img/'+ str(pid)+ '.jpg',\"wb\") as h:\n",
    "                    img=f.read()\n",
    "                    h.write(img)\n",
    "            \n",
    "            driver.switch_to_window(tabs[2]) #ì„¸ë²ˆì§¸ íƒ­ìœ¼ë¡œ ì´ë™\n",
    "            scroll()\n",
    "            driver.get(info_url)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            \n",
    "            writer_name = soup.find('span',{'class':'artist_card__label'}).get_text(strip=True)\n",
    "            writer_name = writer_name.replace(\" \",\"\")\n",
    "            \n",
    "            product_name = soup.find('h2',{'class':'sticky_aside__produc-title'}).text\n",
    "            \n",
    "            detail_info = soup.find('div',{'class':'product-detail-info'})\n",
    "            \n",
    "            product_price = detail_info.find('strong',{'class':'sold-price'}).text.replace(\",\",\"\")\n",
    "            product_price=int(product_price)\n",
    "            \n",
    "            try:\n",
    "                product_hit = detail_info.find('p',{'class':'star-count-text'}).get_text(strip=True)\n",
    "                product_hit = product_hit.replace(\",\",\"\")\n",
    "                product_hit=int(product_hit)\n",
    "            except:\n",
    "                product_hit=0\n",
    "\n",
    "            try:\n",
    "                product_purchase = detail_info.find('span',{'id':'count_up'}).text\n",
    "                product_purchase = product_purchase.replace(\" \",\"\").replace(\"ëª…\",\"\").replace(\",\",\"\")\n",
    "                product_purchase = int(product_purchase)\n",
    "            except:\n",
    "                product_purchase=0\n",
    "            \n",
    "            try:\n",
    "                point_info = detail_info.find('td',{'class':'data-row__content'})\n",
    "                product_point = point_info.find({'span':'data-v-9e98616a'},{'class':'bold-txt'}).text\n",
    "                product_point = product_point.replace(\" \",\"\").replace(\"ìµœ\",\"\").replace(\"ëŒ€\",\"\").replace(\"P\",\"\").replace(\",\",\"\")\n",
    "                product_point=int(product_point)\n",
    "            except:\n",
    "                product_point=0\n",
    "            \n",
    "            try:\n",
    "                product_rate = detail_info.find('span',{'class':'ui_rating fr'})\n",
    "                product_rate = product_rate[\"data-value\"]\n",
    "            except:\n",
    "                product_rate=0\n",
    "            \n",
    "            try:\n",
    "                product_review = detail_info.find('div',{'style':'margin-left: 3px;'}).text\n",
    "                product_review = product_review.replace(\")\",\"\").replace(\"(\",\"\")\n",
    "                product_review = int(product_review)\n",
    "            except:\n",
    "                product_review=0\n",
    "            \n",
    "#             delivery_info = detail_info.find('td',{'class':'data-row__content'})\n",
    "#             product_delivery = delivery_info.find({'span':'data-v-9e98616a'}).get_text(strip=True)\n",
    "#             product_delivery = product_delivery.replace(\",\",\"\").replace(\"ì›\",\"\")\n",
    "            \n",
    "            product_description = soup.findAll('p',{'class':'para'})\n",
    "            \n",
    "            save = [cid,pid,product_name,writer_name,product_price,product_point,product_review,product_hit,3]\n",
    "            print(save)\n",
    "            myWriter.writerow(save)\n",
    "            \n",
    "with open (\"ourdus_product_image.csv\", 'w', encoding='utf-8',newline=\"\") as fileWrite:\n",
    "    myWriter = csv.writer(fileWrite) \n",
    "    for img in img_List:\n",
    "        myWriter.writerow(img)\n",
    "\n",
    "driver.close()\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
